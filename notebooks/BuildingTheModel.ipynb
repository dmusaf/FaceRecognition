{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e94ed091-0ccd-490b-9637-8bc15003cdd1",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c93c932-a678-4223-b5cf-5534b8910c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.10 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39498239-560f-4373-87ab-85778c62b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b4d574-2893-4753-b974-ab27c4587704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't see any GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(gpus) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a00cf8-a204-4417-935a-5abf33cbaaac",
   "metadata": {},
   "source": [
    "## Data Loading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34585ce0-87e2-481f-b9be-43120b53748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 300\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6153210-e826-4d32-b869-bc9043e87802",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(SAMPLE_SIZE)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(SAMPLE_SIZE)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e74a15-9e5d-495b-9749-f9b0e20055f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (100, 100))\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c39598b-f563-4c71-af78-0ff73c876b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negative = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dffc38b7-c6ff-446e-ba76-b3574f83f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return (preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a91019c7-9034-4d10-93df-786252b0b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8a22a6a-5238-4301-a09c-5b5774316504",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d39a801-9d74-4c45-b79c-1617843bb86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.skip(round(len(data)*0.7))\n",
    "test_data = test_data.take(round(len(data)*.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfef683-2eee-41fc-94fe-df2416ba2e4f",
   "metadata": {},
   "source": [
    "## Model building\n",
    "\n",
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a055c6d4-5a18-42d8-9146-4e8b62bcded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inp = Input(shape=(100, 100, 3), name='input_image')\n",
    "    \n",
    "    conv1 = Conv2D(64, (10, 10), activation='relu')(inp)\n",
    "    max_pool1 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, (7, 7), activation='relu')(max_pool1)\n",
    "    max_pool2 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (4, 4), activation='relu')(max_pool2)\n",
    "    max_pool3 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, (4, 4), activation='relu')(max_pool3)\n",
    "    feature_vector = Flatten()(conv4)\n",
    "    fc_1 = Dense(4096, activation='sigmoid')(feature_vector)\n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[fc_1], name='embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea16483-ebf9-4ebb-9b42-9644732c08ca",
   "metadata": {},
   "source": [
    "### Distance layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3814a46-9d0f-4ef1-95eb-df5014349d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "    \n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a2efc-7873-4ca0-ad95-0e851f33802e",
   "metadata": {},
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9e38749-3bdb-47f9-a44a-a59682ee9eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = make_embedding()\n",
    "l1 = L1Dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5cbb486-7f84-47dc-a8bd-17994bca8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    input_image = Input(name='input_img', shape=(100, 100, 3))\n",
    "    validation_image = Input(name='validation_img', shape=(100, 100, 3))\n",
    "    \n",
    "    input_embedding = embedding(input_image)\n",
    "    validation_embedding = embedding(validation_image)\n",
    "    \n",
    "    distances = l1(input_embedding, validation_embedding)\n",
    "    \n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs=[input_image, validation_image], outputs=[classifier], name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "021bff0f-d136-4f5c-a3fb-880f1dc0ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa7ee904-2e40-4633-b0c1-c8d9efe20554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_img (InputLayer)         [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation_img (InputLayer)    [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
      "                                                                  'validation_img[0][0]']         \n",
      "                                                                                                  \n",
      " l1_dist_2 (L1Dist)             (None, 4096)         0           ['embedding[6][0]',              \n",
      "                                                                  'embedding[7][0]']              \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            4097        ['l1_dist_2[1][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
